{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pinn import *\n",
    "from nn import NN\n",
    "from read_write import resolve_json, get_params_PINN\n",
    "\n",
    "retrain_init = False\n",
    "torch.set_default_dtype(torch.float32)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolve_json('par.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if retrain_init:\n",
    "    %run initialization_NN.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "yYakGVopXcjP",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "rho = 0.5\n",
    "mu = 79300 # MPa\n",
    "lam = 100000 # MPa\n",
    "\n",
    "Lx, Ly, T, n_train, layers, dim_hidden, lr, epochs, weight_IN, weight_BOUND = get_params_PINN('par_resolved.json')\n",
    "\n",
    "x_domain = np.array([0.0, Lx])/Lx\n",
    "y_domain = np.array([0.0, Ly])/Lx\n",
    "t_domain = np.array([0.0, T])/T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pinn = PINN(layers, dim_hidden, act=nn.Tanh()).to(device)\n",
    "\n",
    "loss_fn = Loss(\n",
    "    x_domain,\n",
    "    y_domain,\n",
    "    t_domain,\n",
    "    n_train,\n",
    "    return_adim(x_domain, t_domain, rho, mu, lam),\n",
    "    initial_conditions,\n",
    "    weight_IN,\n",
    "    weight_BOUND\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import weights from pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename_model = get_last_modified_file('in_model')\n",
    "pretrained_model_dict = torch.load(filename_model, map_location=torch.device(device))\n",
    "\n",
    "pretrained_model = NN(layers, dim_hidden, 2, 1)\n",
    "pretrained_model.load_state_dict(pretrained_model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in np.arange(len(pinn.middle_layers)):\n",
    "    pinn_layer = pinn.middle_layers[i]\n",
    "    pretrained_layer = pretrained_model.middle_layers[i]\n",
    "    pinn.middle_layers[i].weight.data.copy_(pretrained_model.middle_layers[i].weight)\n",
    "    pinn.middle_layers[i].bias.data.copy_(pretrained_model.middle_layers[i].bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train new network with pretrained weights and biases in middle layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5qEPIGzEXj0b",
    "outputId": "4555c285-89a5-4e4f-ff57-1560c4f910b1",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder '2024-04-30' already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.6323e+12:   0%|          | 4/50000 [00:15<51:19:56,  3.70s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pinn_trained, loss_values \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpinn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/EvolBERNPINN2D/pinn.py:295\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(nn_approximator, loss_fn, learning_rate, max_epochs)\u001b[0m\n\u001b[1;32m    292\u001b[0m grads \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    294\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 295\u001b[0m _, residual_loss, initial_loss, boundary_loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnn_approximator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m loss: torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m=\u001b[39m loss_fn(nn_approximator)\n\u001b[1;32m    298\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/EvolBERNPINN2D/pinn.py:240\u001b[0m, in \u001b[0;36mLoss.verbose\u001b[0;34m(self, pinn)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mverbose\u001b[39m(\u001b[38;5;28mself\u001b[39m, pinn: PINN):\n\u001b[1;32m    235\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;124;03m    Returns all parts of the loss function\u001b[39;00m\n\u001b[1;32m    237\u001b[0m \n\u001b[1;32m    238\u001b[0m \u001b[38;5;124;03m    Not used during training! Only for checking the results later.\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 240\u001b[0m     residual_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresidual_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpinn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m     initial_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitial_loss(pinn)\n\u001b[1;32m    242\u001b[0m     boundary_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mboundary_loss(pinn)\n",
      "File \u001b[0;32m~/EvolBERNPINN2D/pinn.py:163\u001b[0m, in \u001b[0;36mLoss.residual_loss\u001b[0;34m(self, pinn)\u001b[0m\n\u001b[1;32m    160\u001b[0m dux_tt \u001b[38;5;241m=\u001b[39m df(output, [t, t], \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    161\u001b[0m duy_tt \u001b[38;5;241m=\u001b[39m df(output, [t, t], \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 163\u001b[0m dux_xx \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m duy_yy \u001b[38;5;241m=\u001b[39m df(output, [y, y], \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    166\u001b[0m dux_xy \u001b[38;5;241m=\u001b[39m df(output, [x, y], \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/EvolBERNPINN2D/pinn.py:126\u001b[0m, in \u001b[0;36mdf\u001b[0;34m(output, inputs, var)\u001b[0m\n\u001b[1;32m    124\u001b[0m df_value \u001b[38;5;241m=\u001b[39m output[:, var]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(inputs)):\n\u001b[0;32m--> 126\u001b[0m     df_value \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdf_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[43m_\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[43m_\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df_value\n",
      "File \u001b[0;32m~/.conda/envs/EvolBern/lib/python3.9/site-packages/torch/autograd/__init__.py:412\u001b[0m, in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched, materialize_grads)\u001b[0m\n\u001b[1;32m    408\u001b[0m     result \u001b[38;5;241m=\u001b[39m _vmap_internals\u001b[38;5;241m.\u001b[39m_vmap(vjp, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, allow_none_pass_through\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(\n\u001b[1;32m    409\u001b[0m         grad_outputs_\n\u001b[1;32m    410\u001b[0m     )\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 412\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_outputs_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m materialize_grads:\n\u001b[1;32m    422\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[1;32m    423\u001b[0m         result[i] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tensor_like(inputs[i])\n\u001b[1;32m    424\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(inputs))\n\u001b[1;32m    425\u001b[0m     ):\n",
      "File \u001b[0;32m~/.conda/envs/EvolBern/lib/python3.9/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pinn_trained, loss_values = train_model(\n",
    "    pinn, loss_fn=loss_fn, learning_rate=lr, max_epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tp5m_1mJ0By3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "current_time = get_current_time(fmt=\"%H:%M\")\n",
    "\n",
    "folder = 'model'\n",
    "model_name = f'{lr}_{epochs}_{dim_hidden}_{current_time}.pth'\n",
    "model_path = os.path.join(folder, model_name)\n",
    "os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "torch.save(pinn_trained.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "yvHawzyAYkuW",
    "outputId": "4c3a7757-9298-4fe9-c1cb-1d159dc184ea",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from plots import plot_initial_conditions, plot_solution\n",
    "\n",
    "x, y, _ = get_initial_points(x_domain, y_domain, t_domain, n_train)\n",
    "t_value = 0.0\n",
    "t = torch.full_like(x, t_value)\n",
    "x = x.to(device)\n",
    "y = y.to(device)\n",
    "t = t.to(device)\n",
    "z = f(pinn_trained, x ,y, t)\n",
    "ux_0, uy_0 = initial_conditions(x, y, Lx, i = 1)\n",
    "z_0 = torch.cat((ux_0, uy_0), dim=1)\n",
    "\n",
    "plot_initial_conditions(z_0, y, x, 'Initial conditions - analytical', n_train, from_pinn = 0)\n",
    "plot_initial_conditions(z, y, x, 'Initial conditions - NN', n_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "x, y, t = get_interior_points(x_domain, y_domain, t_domain, n_train)\n",
    "animation = plot_solution(pinn, x, y, t, n_train)\n",
    "HTML(animation.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9hqnVSEf3dgC"
   },
   "source": [
    "# To be added\n",
    "- ~separate loss in more bars to see how the various loss term come to zero~\n",
    "- see if some quadrature rule has been implemented\n",
    "- scheme of weights initialization in order to automatically satisfy initial conditions\n",
    "- plots (in progress)\n",
    "- NN operators (to generalize results)\n",
    "- try to implement function that allows that satisfy initial conditions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OLyts7jbh2i4"
   },
   "source": [
    "# To be fully understood\n",
    "- reshape when plotting (also different number of points allowed?)\n",
    "- ~not consistent initial conditions~ (between $u_x$ and $u_y$)?"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "EvolBern:Python",
   "language": "python",
   "name": "conda-env-EvolBern-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc-autonumbering": false,
  "toc-showcode": true,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
