{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pinn import *\n",
    "from nn import NN\n",
    "import numpy as np\n",
    "from read_write import resolve_json, get_params_PINN, get_params_mat, get_last_modified_file, pass_folder\n",
    "\n",
    "retrain_init = False\n",
    "retrain_PINN = True\n",
    "\n",
    "torch.set_default_dtype(torch.float32)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolve_json('par.j2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if retrain_init:\n",
    "    %run initialization_NN.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "yYakGVopXcjP",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from initialize_matpar import to_matpar_PINN\n",
    "\n",
    "E, rho, _ , nu = get_params_mat('par_resolved.json')\n",
    "\n",
    "lam, mu = to_matpar_PINN(E, nu)\n",
    "\n",
    "Lx, Ly, T, n_train, layers, dim_hidden, lr, epochs, weight_IN, weight_BOUND = get_params_PINN('par_resolved.json')\n",
    "\n",
    "x_domain = np.array([0.0, Lx])/Lx\n",
    "y_domain = np.array([0.0, Ly])/Lx\n",
    "t_domain = np.array([0.0, T])/T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pinn = PINN(layers, dim_hidden, act=nn.Tanh()).to(device)\n",
    "\n",
    "loss_fn = Loss(\n",
    "    x_domain,\n",
    "    y_domain,\n",
    "    t_domain,\n",
    "    n_train,\n",
    "    return_adim(x_domain, t_domain, rho, mu, lam),\n",
    "    initial_conditions,\n",
    "    weight_IN,\n",
    "    weight_BOUND\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder 'model/05-03/12:56' created successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.57:   5%|â–Œ         | 80/1500 [00:10<03:02,  7.78it/s]  "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m     pinn\u001b[38;5;241m.\u001b[39mmiddle_layers[i]\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mcopy_(pretrained_model\u001b[38;5;241m.\u001b[39mmiddle_layers[i]\u001b[38;5;241m.\u001b[39mweight)\n\u001b[1;32m     27\u001b[0m     pinn\u001b[38;5;241m.\u001b[39mmiddle_layers[i]\u001b[38;5;241m.\u001b[39mbias\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mcopy_(pretrained_model\u001b[38;5;241m.\u001b[39mmiddle_layers[i]\u001b[38;5;241m.\u001b[39mbias)\n\u001b[0;32m---> 29\u001b[0m pinn_trained, loss_values \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m\u001b[49m\u001b[43mpinn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdim_hidden\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     33\u001b[0m model_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path, model_name)\n",
      "File \u001b[0;32m~/EvolBERNPINN2D/pinn.py:277\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(nn_approximator, loss_fn, learning_rate, max_epochs, path)\u001b[0m\n\u001b[1;32m    274\u001b[0m _, residual_loss, initial_loss, boundary_loss \u001b[38;5;241m=\u001b[39m loss_fn\u001b[38;5;241m.\u001b[39mverbose(nn_approximator)\n\u001b[1;32m    275\u001b[0m loss: torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m=\u001b[39m loss_fn(nn_approximator)\n\u001b[0;32m--> 277\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    278\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    280\u001b[0m loss_values\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[0;32m~/.conda/envs/EvolBern/lib/python3.9/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/EvolBern/lib/python3.9/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/EvolBern/lib/python3.9/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "path = pass_folder()\n",
    "\n",
    "if retrain_PINN:\n",
    "    pinn = PINN(layers, dim_hidden, act=nn.Tanh()).to(device)\n",
    "\n",
    "    loss_fn = Loss(\n",
    "        x_domain,\n",
    "        y_domain,\n",
    "        t_domain,\n",
    "        n_train,\n",
    "        return_adim(x_domain, t_domain, rho, mu, lam),\n",
    "        initial_conditions,\n",
    "        weight_IN,\n",
    "        weight_BOUND\n",
    "    )\n",
    "    \n",
    "    filename_model = get_last_modified_file('in_model')\n",
    "    pretrained_model_dict = torch.load(filename_model, map_location=torch.device(device))\n",
    "\n",
    "    pretrained_model = NN(layers, dim_hidden, 2, 1)\n",
    "    pretrained_model.load_state_dict(pretrained_model_dict)\n",
    "\n",
    "    for i in np.arange(len(pinn.middle_layers)):\n",
    "        pinn_layer = pinn.middle_layers[i]\n",
    "        pretrained_layer = pretrained_model.middle_layers[i]\n",
    "        pinn.middle_layers[i].weight.data.copy_(pretrained_model.middle_layers[i].weight)\n",
    "        pinn.middle_layers[i].bias.data.copy_(pretrained_model.middle_layers[i].bias)\n",
    "\n",
    "    pinn_trained, loss_values = train_model(\n",
    "    pinn, loss_fn=loss_fn, learning_rate=lr, max_epochs=epochs, path=path)\n",
    "    \n",
    "    model_name = f'{lr}_{epochs}_{dim_hidden}.pth'\n",
    "    model_path = os.path.join(path, model_name)\n",
    "    \n",
    "    torch.save(pinn_trained.state_dict(), model_path)\n",
    "    \n",
    "else:\n",
    "    pinn_trained = PINN(layers, dim_hidden, act=nn.Tanh()).to(device)\n",
    "    filename = get_last_modified_file('model')\n",
    "    pinn_trained.load_state_dict(torch.load(filename, map_location = device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train new network with pretrained weights and biases in middle layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinn_trained.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "yvHawzyAYkuW",
    "outputId": "4c3a7757-9298-4fe9-c1cb-1d159dc184ea",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from plots import plot_initial_conditions, plot_uy\n",
    "\n",
    "x, y, _ = get_initial_points(x_domain, y_domain, t_domain, n_train)\n",
    "t_value = 0.0\n",
    "t = torch.full_like(x, t_value)\n",
    "x = x.to(device)\n",
    "y = y.to(device)\n",
    "t = t.to(device)\n",
    "z = f(pinn_trained, x ,y, t)\n",
    "ux_0, uy_0 = initial_conditions(x, y, Lx, i = 1)\n",
    "z_0 = torch.cat((ux_0, uy_0), dim=1)\n",
    "\n",
    "plot_initial_conditions(z_0, y, x, 'Initial conditions - analytical', n_train, from_pinn = 0)\n",
    "plot_initial_conditions(z, y, x, 'Initial conditions - NN', n_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, t = get_interior_points(x_domain, y_domain, t_domain, n_train)\n",
    "plot_uy(pinn_trained, x, y, t, n_train, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9hqnVSEf3dgC"
   },
   "source": [
    "# To be added\n",
    "- ~separate loss in more bars to see how the various loss term come to zero~\n",
    "- see if some quadrature rule has been implemented\n",
    "- scheme of weights initialization in order to automatically satisfy initial conditions\n",
    "- plots (in progress)\n",
    "- NN operators (to generalize results)\n",
    "- try to implement function that allows that satisfy initial conditions?"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "EvolBern:Python",
   "language": "python",
   "name": "conda-env-EvolBern-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc-autonumbering": false,
  "toc-showcode": true,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
