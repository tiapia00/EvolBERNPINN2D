{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "9dsfXNOXX0mz",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from typing import Tuple\n",
    "import os\n",
    "\n",
    "torch.set_default_dtype(torch.float32)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_modified_file(folder_path):\n",
    "    # Get a list of all files in the folder\n",
    "    files = os.listdir(folder_path)\n",
    "\n",
    "    if not files:\n",
    "        return None  # Return None if the folder is empty\n",
    "\n",
    "    # Initialize variables to keep track of the most recently modified file\n",
    "    last_modified_file = None\n",
    "    last_modified_time = 0\n",
    "\n",
    "    # Iterate over each file in the folder\n",
    "    for file_name in files:\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "        # Check if the current path is a file (not a directory)\n",
    "        if os.path.isfile(file_path):\n",
    "            # Get the modification time of the file\n",
    "            file_modified_time = os.path.getmtime(file_path)\n",
    "\n",
    "            # Compare with the last modified time found\n",
    "            if file_modified_time > last_modified_time:\n",
    "                last_modified_time = file_modified_time\n",
    "                last_modified_file = file_path\n",
    "                \n",
    "\n",
    "    return last_modified_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "LS5TpzjbXEIV",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def initial_conditions(x: torch.tensor, y : torch.tensor, Lx: float, i: float = 1) -> torch.tensor:\n",
    "    # description of displacements, so i don't have to add anything\n",
    "    res_ux = torch.zeros_like(x)\n",
    "    res_uy = torch.sin(torch.pi*i/x[-1]*x)/Lx\n",
    "    return res_ux, res_uy\n",
    "\n",
    "def get_initial_points(x_domain, y_domain, t_domain, n_points, device = torch.device(device), requires_grad=True):\n",
    "    x_linspace = torch.linspace(x_domain[0], x_domain[1], n_points)\n",
    "    y_linspace = torch.linspace(y_domain[0], y_domain[1], n_points)\n",
    "    x_grid, y_grid = torch.meshgrid(x_linspace, y_linspace, indexing=\"ij\")\n",
    "    x_grid = x_grid.reshape(-1, 1).to(device)\n",
    "    x_grid.requires_grad = requires_grad\n",
    "    y_grid = y_grid.reshape(-1, 1).to(device)\n",
    "    y_grid.requires_grad = requires_grad\n",
    "    t0 = torch.full_like(x_grid, t_domain[0], requires_grad=requires_grad)\n",
    "    return (x_grid, y_grid, t0)\n",
    "\n",
    "def get_boundary_points(x_domain, y_domain, t_domain, n_points, device = torch.device(device), requires_grad=True):\n",
    "    \"\"\"\n",
    "         .+------+\n",
    "       .' |    .'|\n",
    "      +---+--+'  |\n",
    "      |   |  |   |\n",
    "    x |  ,+--+---+\n",
    "      |.'    | .' t\n",
    "      +------+'\n",
    "         y\n",
    "    down , up : extremes of the beam\n",
    "    \"\"\"\n",
    "    x_linspace = torch.linspace(x_domain[0], x_domain[1], n_points)\n",
    "    y_linspace = torch.linspace(y_domain[0], y_domain[1], n_points)\n",
    "    t_linspace = torch.linspace(t_domain[0], t_domain[1], n_points)\n",
    "\n",
    "    x_grid, t_grid = torch.meshgrid(x_linspace, t_linspace, indexing=\"ij\")\n",
    "    y_grid, _      = torch.meshgrid(y_linspace, t_linspace, indexing=\"ij\")\n",
    "\n",
    "    x_grid = x_grid.reshape(-1, 1).to(device)\n",
    "    x_grid.requires_grad = requires_grad\n",
    "    y_grid = y_grid.reshape(-1, 1).to(device)\n",
    "    y_grid.requires_grad = requires_grad\n",
    "    t_grid = t_grid.reshape(-1, 1).to(device)\n",
    "    t_grid.requires_grad = requires_grad\n",
    "\n",
    "    x0 = torch.full_like(t_grid, x_domain[0], requires_grad=requires_grad)\n",
    "    x1 = torch.full_like(t_grid, x_domain[1], requires_grad=requires_grad)\n",
    "    y0 = torch.full_like(t_grid, y_domain[0], requires_grad=requires_grad)\n",
    "    y1 = torch.full_like(t_grid, y_domain[1], requires_grad=requires_grad)\n",
    "\n",
    "    down    = (y_grid, x0,     t_grid)\n",
    "    up      = (y_grid, x1,     t_grid)\n",
    "    left    = (y0,     x_grid, t_grid)\n",
    "    right   = (y1,     x_grid, t_grid)\n",
    "\n",
    "    return down, up, left, right\n",
    "\n",
    "def get_interior_points(x_domain, y_domain, t_domain, n_points, device = torch.device(device), requires_grad=True):\n",
    "    x_raw = torch.linspace(x_domain[0], x_domain[1], steps=n_points, requires_grad=requires_grad)\n",
    "    y_raw = torch.linspace(y_domain[0], y_domain[1], steps=n_points, requires_grad=requires_grad)\n",
    "    t_raw = torch.linspace(t_domain[0], t_domain[1], steps=n_points, requires_grad=requires_grad)\n",
    "    grids = torch.meshgrid(x_raw, y_raw, t_raw, indexing=\"ij\")\n",
    "\n",
    "    x = grids[0].reshape(-1, 1).to(device)\n",
    "    y = grids[1].reshape(-1, 1).to(device)\n",
    "    t = grids[2].reshape(-1, 1).to(device)\n",
    "\n",
    "    return x, y, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "c08OZa86XH1p",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PINN(nn.Module):\n",
    "    \"\"\"Simple neural network accepting two features as input and returning a single output\n",
    "\n",
    "    In the context of PINNs, the neural network is used as universal function approximator\n",
    "    to approximate the solution of the differential equation\n",
    "    \"\"\"\n",
    "    def __init__(self, num_hidden: int, dim_hidden: int, dim_input : int = 3, dim_output : int = 2, act=nn.Tanh()):\n",
    "\n",
    "        super().__init__()\n",
    "        self.dim_hidden = dim_hidden\n",
    "        self.layer_in = nn.Linear(dim_input, self.dim_hidden)\n",
    "        \n",
    "        self.num_middle = num_hidden - 1\n",
    "        self.middle_layers = nn.ModuleList()\n",
    "\n",
    "        for _ in range(self.num_middle):\n",
    "            middle_layer = nn.Linear(dim_hidden, dim_hidden)\n",
    "            self.act = act\n",
    "            self.middle_layers.append(middle_layer)\n",
    "\n",
    "        self.layer_out = nn.Linear(dim_hidden, dim_output)\n",
    "\n",
    "    def forward(self, x, y, t):\n",
    "\n",
    "        x_stack = torch.cat([x, y, t], dim=1)\n",
    "        out = self.act(self.layer_in(x_stack))\n",
    "        for layer in self.middle_layers:\n",
    "            out = self.act(layer(out))\n",
    "        logits = self.layer_out(out)\n",
    "\n",
    "        return logits\n",
    "\n",
    "    def device(self):\n",
    "        return next(self.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "XJzpNHjJzwRY",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def f(pinn: PINN, x: torch.Tensor, y: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Compute the value of the approximate solution from the NN model\n",
    "    Internally calling the forward method when calling the class as a function\"\"\"\n",
    "    return pinn(x, y, t)\n",
    "\n",
    "def df(output: torch.Tensor, inputs: list, var : int) -> torch.Tensor:\n",
    "    \"\"\"Compute neural network derivative with respect to input features using PyTorch autograd engine\n",
    "    var = 0 : dux\n",
    "    var = 1 : duy\n",
    "    \"\"\"\n",
    "    df_value = output[:, var].unsqueeze(1)\n",
    "    for _ in np.arange(len(inputs)):\n",
    "        df_value = torch.autograd.grad(\n",
    "            df_value,\n",
    "            inputs[_],\n",
    "            grad_outputs=torch.ones_like(inputs[_]),\n",
    "            create_graph=True,\n",
    "            retain_graph=True,\n",
    "        )[0]\n",
    "\n",
    "    return df_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "NCSe1fU_zrF9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Loss:\n",
    "    def __init__(\n",
    "        self,\n",
    "        x_domain: Tuple[float, float],\n",
    "        y_domain: Tuple[float, float],\n",
    "        t_domain: Tuple[float, float],\n",
    "        n_points: int,\n",
    "        z : torch.tensor,\n",
    "        initial_condition: Callable,\n",
    "        weight_r: float = 1.0,\n",
    "        weight_b: float = 1.0,\n",
    "        weight_i: float = 1.0,\n",
    "        verbose: bool = False,\n",
    "    ):\n",
    "        self.x_domain = x_domain\n",
    "        self.y_domain = y_domain\n",
    "        self.t_domain = t_domain\n",
    "        self.n_points = n_points\n",
    "        self.z = z\n",
    "        self.initial_condition = initial_condition\n",
    "        self.weight_r = weight_r\n",
    "        self.weight_b = weight_b\n",
    "        self.weight_i = weight_i\n",
    "        \n",
    "\n",
    "    def residual_loss(self, pinn: PINN):\n",
    "        x, y, t = get_interior_points(self.x_domain, self.y_domain, self.t_domain, self.n_points, pinn.device())\n",
    "        output = f(pinn, x, y, t)\n",
    "        dux_tt = df(output, [t, t], 0)\n",
    "        duy_tt = df(output, [t, t], 1)\n",
    "\n",
    "        dux_xx = df(output, [x, x], 0)\n",
    "        duy_yy = df(output, [y, y], 1)\n",
    "\n",
    "        dux_xy = df(output, [x, y], 0)\n",
    "        duy_xy = df(output, [x, y], 1)\n",
    "\n",
    "        loss1 = dux_tt - 2*self.z[0]*(dux_xx+1/2*(duy_xy+dux_xy)) - self.z[1]*(dux_xx+duy_xy)\n",
    "        loss2 = duy_tt - 2*self.z[0]*(1/2*(dux_xy+duy_xy)+duy_yy) - self.z[1]*(dux_xy+duy_yy)\n",
    "        return self.weight_r*(loss1.pow(2).mean() + loss2.pow(2).mean())\n",
    "\n",
    "    def initial_loss(self, pinn: PINN):\n",
    "        x, y, t = get_initial_points(self.x_domain, self.y_domain, self.t_domain, self.n_points, pinn.device())\n",
    "        pinn_init_ux, pinn_init_uy = self.initial_condition(x, y, x[-1])\n",
    "        output = f(pinn, x, y, t)\n",
    "        ux = output[:, 0]\n",
    "        uy = output[:, 1]\n",
    "        loss1 = ux - pinn_init_ux\n",
    "        loss2 = uy - pinn_init_uy\n",
    "        return self.weight_i*(loss1.pow(2).mean() + loss2.pow(2).mean())\n",
    "\n",
    "    def boundary_loss(self, pinn: PINN):\n",
    "        \"\"\"For now,\n",
    "            - down, up: Dirichlet conditions\n",
    "            - left, right : Neumann conditions\"\"\"\n",
    "        # n (normal vector) assumed constant during deformation\n",
    "\n",
    "        down, up, left, right = get_boundary_points(self.x_domain, self.y_domain, self.t_domain, self.n_points, pinn.device())\n",
    "        x_down,  y_down,  t_down    = down\n",
    "        x_up,    y_up,    t_up      = up\n",
    "        x_left,  y_left,  t_left    = left\n",
    "        x_right, y_right, t_right   = right\n",
    "\n",
    "        # Dirichlet conditions on both functions\n",
    "        loss_down1 = f(pinn, x_down, y_down, t_down)[:,0]\n",
    "        loss_down2 = f(pinn, x_down, y_down, t_down)[:,1]\n",
    "        loss_up1 = f(pinn, x_up, y_up, t_up)[:,0]\n",
    "        loss_up2 = f(pinn, x_up, y_up, t_up)[:,1]\n",
    "\n",
    "        ux_left = f(pinn, x_left, y_left, t_left)[:,0]\n",
    "        uy_left = f(pinn, x_left, y_left, t_left)[:,1]\n",
    "\n",
    "        left = torch.cat([ux_left[..., None], uy_left[..., None]], -1)\n",
    "        duy_y_left = df(left, [y_left], 1)\n",
    "        dux_y_left = df(left, [y_left], 0)\n",
    "        duy_x_left = df(left, [x_left], 1)\n",
    "        tr_left = df(left, [x_left], 0) + duy_y_left\n",
    "\n",
    "        ux_right = f(pinn, x_right, y_right, t_right)[:,0]\n",
    "        uy_right = f(pinn, x_right, y_right, t_right)[:,1]\n",
    "\n",
    "        right = torch.cat([ux_right[..., None], uy_right[..., None]], -1)\n",
    "        duy_y_right = df(right, [y_right], 1)\n",
    "        dux_y_right = df(right, [y_right], 0)\n",
    "        duy_x_right = df(right, [x_right], 1)\n",
    "        tr_right = df(right, [x_right], 0) + duy_y_right\n",
    "\n",
    "        loss_left1  = 2*self.z[0]*(1/2*(dux_y_left+duy_x_left))\n",
    "        loss_left2 =  2*self.z[0]*duy_y_left+self.z[1]*tr_left\n",
    "\n",
    "        loss_right1 = 2*self.z[0]*(1/2*(dux_y_right+duy_x_right))\n",
    "        loss_right2 = 2*self.z[0]*duy_y_right+self.z[1]*tr_right\n",
    "\n",
    "        return self.weight_b*(loss_left1.pow(2).mean()  + \\\n",
    "            loss_left2.pow(2).mean()    + \\\n",
    "            loss_right1.pow(2).mean()  + \\\n",
    "            loss_right2.pow(2).mean()  + \\\n",
    "            loss_down1.pow(2).mean()   + \\\n",
    "            loss_down2.pow(2).mean()    + \\\n",
    "            loss_up1.pow(2).mean()      + \\\n",
    "            loss_up2.pow(2).mean())\n",
    "\n",
    "    def verbose(self, pinn: PINN):\n",
    "        \"\"\"\n",
    "        Returns all parts of the loss function\n",
    "\n",
    "        Not used during training! Only for checking the results later.\n",
    "        \"\"\"\n",
    "        residual_loss = self.residual_loss(pinn)\n",
    "        initial_loss = self.initial_loss(pinn)\n",
    "        boundary_loss = self.boundary_loss(pinn)\n",
    "\n",
    "        final_loss = \\\n",
    "            self.weight_r * residual_loss + \\\n",
    "            self.weight_i * initial_loss + \\\n",
    "            self.weight_b * boundary_loss\n",
    "\n",
    "        return final_loss, residual_loss, initial_loss, boundary_loss\n",
    "\n",
    "    def __call__(self, pinn: PINN):\n",
    "        \"\"\"\n",
    "        Allows you to use instance of this class as if it was a function:\n",
    "\n",
    "        ```\n",
    "            >>> loss = Loss(*some_args)\n",
    "            >>> calculated_loss = loss(pinn)\n",
    "        ```\n",
    "        \"\"\"\n",
    "        return self.verbose(pinn)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "VlZM8yATXS0n",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "from datetime import date\n",
    "import datetime\n",
    "import pytz\n",
    "\n",
    "def create_folder_date(directory, folder_name):\n",
    "    folder_path = os.path.join(directory, folder_name)\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "        print(f\"Folder '{folder_name}' created.\")\n",
    "    else:\n",
    "        print(f\"Folder '{folder_name}' already exists.\")\n",
    "        \n",
    "def get_current_time():\n",
    "    current_time_utc = datetime.datetime.utcnow()\n",
    "    target_timezone = pytz.timezone('Europe/Paris')\n",
    "    return current_time_utc.astimezone(target_timezone)\n",
    "\n",
    "def train_model(\n",
    "    nn_approximator: PINN,\n",
    "    loss_fn: Callable,\n",
    "    learning_rate: int,\n",
    "    max_epochs: int\n",
    ") -> PINN:\n",
    "    \n",
    "    folder_name = date.today().isoformat()\n",
    "    \n",
    "    create_folder_date('logs', folder_name)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(nn_approximator.parameters(), lr=learning_rate)\n",
    "    loss_values = []\n",
    "    loss: torch.Tensor = torch.inf\n",
    "\n",
    "    # Logging\n",
    "\n",
    "    pbar = tqdm(total=max_epochs, desc=\"Training\", position=0)\n",
    "    log_dir = f'logs/{folder_name}'\n",
    "\n",
    "    current_time = get_current_time()\n",
    "    subfolder = '/' + current_time.strftime(\"%H:%M\")\n",
    "    writer = SummaryWriter(log_dir=log_dir + f'/lr = {learning_rate}, max_e = {max_epochs}, hidden_n = {nn_approximator.dim_hidden}' + subfolder)\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "\n",
    "        loss: torch.Tensor = loss_fn(nn_approximator)\n",
    "        _, residual_loss, initial_loss, boundary_loss = loss_fn.verbose(nn_approximator)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_values.append(loss.item())\n",
    "\n",
    "        # Log loss\n",
    "        pbar.set_description(f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "        writer.add_scalar(\"Global loss\", loss.item(), epoch)\n",
    "        writer.add_scalar(\"Residual loss\", residual_loss.item(), epoch)\n",
    "        writer.add_scalar(\"Initial loss\", initial_loss.item(), epoch)\n",
    "        writer.add_scalar(\"Boundary loss\", boundary_loss.item(), epoch)\n",
    "\n",
    "        pbar.update(1)\n",
    "\n",
    "    pbar.update(1)\n",
    "    pbar.close()\n",
    "    writer.close()\n",
    "    return nn_approximator, np.array(loss_values)\n",
    "\n",
    "def return_adim(x_dom : np.ndarray, t_dom:np.ndarray, rho: float, mu : float, lam : float):\n",
    "    L_ast = x_dom[-1]\n",
    "    T_ast = t_dom[-1]\n",
    "    z_1 = T_ast**2/(L_ast*rho)*mu\n",
    "    z_2 = z_1/mu*lam\n",
    "    z = np.array([z_1, z_2])\n",
    "    z = torch.tensor(z)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Xoqjq6K2V3Va",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.ticker import MaxNLocator, FuncFormatter\n",
    "\n",
    "def plot_initial_conditions(z: torch.tensor, y: torch.tensor, x:torch.tensor, name : str, n_train : int, from_pinn : bool = 1):\n",
    "    \"\"\" For this function, z is the full tensor with both components\"\"\"\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=2, subplot_kw={'projection': '3d'}, figsize=(15, 8))\n",
    "\n",
    "    nbins = 7\n",
    "    x_raw = x.detach().cpu().numpy()\n",
    "    y_raw = y.detach().cpu().numpy()\n",
    "\n",
    "    if from_pinn:\n",
    "        ux_raw = z.detach().cpu().numpy()[:, 0]\n",
    "        uy_raw = z.detach().cpu().numpy()[:, 1]\n",
    "    else:\n",
    "        z = z.cpu()\n",
    "        ux_raw = z.detach().numpy()[:, 0]\n",
    "        uy_raw = z.detach().numpy()[:, 1]\n",
    "\n",
    "    X = x_raw.reshape(n_train, n_train)\n",
    "    Y = y_raw.reshape(n_train, n_train)\n",
    "\n",
    "    ux = ux_raw.reshape(n_train, n_train)\n",
    "    uy = uy_raw.reshape(n_train, n_train)\n",
    "\n",
    "    def format_ticks(value, pos):\n",
    "        return f'{value:.3f}'\n",
    "\n",
    "    cmap = 'viridis'\n",
    "    p1 = ax[0].plot_surface(Y, X, ux, cmap=cmap)\n",
    "    ax[0].set_xlabel('$\\\\hat{y}$')\n",
    "    ax[0].set_ylabel('$\\\\hat{x}$')\n",
    "    ax[0].set_title('$\\\\hat{u}_x$')\n",
    "    ax[0].view_init(elev=30, azim=45)\n",
    "    ax[0].xaxis.set_major_locator(MaxNLocator(nbins=nbins))\n",
    "    ax[0].yaxis.set_major_locator(MaxNLocator(nbins=nbins))\n",
    "    ax[0].zaxis.set_major_locator(MaxNLocator(nbins=nbins-2))\n",
    "    ax[0].xaxis.set_major_formatter(FuncFormatter(format_ticks))\n",
    "    ax[0].yaxis.set_major_formatter(FuncFormatter(format_ticks))\n",
    "    ax[0].zaxis.set_major_formatter(FuncFormatter(format_ticks))\n",
    "    ax[0].set_box_aspect([2, 2, 1])\n",
    "\n",
    "    p2 = ax[1].plot_surface(Y, X, uy, cmap=cmap)\n",
    "    ax[1].set_xlabel('$\\\\hat{y}$')\n",
    "    ax[1].set_ylabel('$\\\\hat{x}$')\n",
    "    ax[1].set_title('$\\\\hat{u}_y$')\n",
    "    ax[1].view_init(elev=30, azim=45)\n",
    "    ax[1].xaxis.set_major_locator(MaxNLocator(nbins=nbins))\n",
    "    ax[1].yaxis.set_major_locator(MaxNLocator(nbins=nbins))\n",
    "    ax[1].zaxis.set_major_locator(MaxNLocator(nbins=nbins-2))\n",
    "    ax[1].xaxis.set_major_formatter(FuncFormatter(format_ticks))\n",
    "    ax[1].yaxis.set_major_formatter(FuncFormatter(format_ticks))\n",
    "    ax[1].zaxis.set_major_formatter(FuncFormatter(format_ticks))\n",
    "    ax[1].set_box_aspect([2, 2, 1])\n",
    "\n",
    "    fig.suptitle(name)\n",
    "\n",
    "def plot_solution(pinn: PINN, x: torch.Tensor, y: torch.Tensor, t: torch.Tensor, n_train : int, figsize=(12, 8), dpi=100):\n",
    "\n",
    "    rc('animation', html='jshtml')\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, subplot_kw={'projection': '3d'}, figsize=(15, 8))\n",
    "    x_raw = x.reshape(n_train, n_train, n_train)\n",
    "    y_raw = y.reshape(n_train, n_train, n_train)\n",
    "    t_raw = torch.unique(t)\n",
    "\n",
    "    def animate(i):\n",
    "\n",
    "        if not i % 10 == 0:\n",
    "            t_partial = torch.ones_like(x_raw) * t_raw[i]\n",
    "            f_final = f(pinn, x_raw, y_raw, t_partial)\n",
    "            ax.clear()\n",
    "            ax.plot(\n",
    "                x_raw.detach().numpy()[:,:,i], y_raw.detach().numpy()[:,:,i], f_final.detach().numpy()[:,0], label=f\"Time {float(t[i])}\"\n",
    "            )\n",
    "            ax.legend()\n",
    "\n",
    "    n_frames = t_raw.shape[0]\n",
    "    return animation.FuncAnimation(fig, animate, frames=n_frames, blit=False, repeat=True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc-autonumbering": false,
  "toc-showcode": true,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
